{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.1 Byte pair encoding of unknown words\n",
    "Try the BPE tokenizer from the tiktoken library on the unknown words “Akwirw ier” and\n",
    "print the individual token IDs. Then, call the decode function on each of the resulting\n",
    "integers in this list to reproduce the mapping shown in figure 2.11. Lastly, call the\n",
    "decode method on the token IDs to check whether it can reconstruct the original\n",
    "input, “Akwirw ier.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs: [33901, 86, 343, 86, 220, 959]\n",
      "Individual token decodings:\n",
      "33901: Ak\n",
      "86: w\n",
      "343: ir\n",
      "86: w\n",
      "220:  \n",
      "959: ier\n",
      "Decoded text: Akwirw ier\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "encoding = tiktoken.get_encoding(\"gpt2\")\n",
    "text = \"Akwirw ier\"\n",
    "\n",
    "token_ids = encoding.encode(text)\n",
    "print(\"Token IDs:\", token_ids)\n",
    "\n",
    "print(\"Individual token decodings:\")\n",
    "for token_id in token_ids:\n",
    "    decoded_token = encoding.decode([token_id])\n",
    "    print(f\"{token_id}: {decoded_token}\")\n",
    "\n",
    "decoded_text = encoding.decode(token_ids)\n",
    "print(\"Decoded text:\", decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2.2 Data loaders with different strides and context sizes\n",
    "To develop more intuition for how the data loader works, try to run it with different\n",
    "settings such as max_length=2 and stride=2, and max_length=8 and stride=2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    " \n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i : i + max_length]\n",
    "            target_chunk = token_ids[i + 1 : i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n",
    "def create_dataloader(txt, batch_size, max_length, stride):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    return DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "# test string\n",
    "sample_text = \"This is a sample text for our data loader test.\"\n",
    "\n",
    "print(\"test：max_length=2, stride=2\")\n",
    "loader1 = create_dataloader(sample_text, batch_size=2, max_length=2, stride=2)\n",
    "for batch in loader1:\n",
    "    inputs, targets = batch\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Targets:\", targets)\n",
    "    break  \n",
    "\n",
    "print(\"\\ntest：max_length=8, stride=2\")\n",
    "loader2 = create_dataloader(sample_text, batch_size=2, max_length=8, stride=2)\n",
    "for batch in loader2:\n",
    "    inputs, targets = batch\n",
    "    print(\"Inputs:\", inputs)\n",
    "    print(\"Targets:\", targets)\n",
    "    break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
